---
layout: post
title: Coding with AI
date: 2023-03-30 17:22 +0100
last_updated: 2023-03-30 17:22 +0100
author: Christoph Kappel
tags: showcase
categories: showcase
toc: true
---
:imagesdir: /assets/images/coding_with_ai

////
https://github.com/features/copilot
https://www.tabnine.com/pricing
https://en.wikipedia.org/wiki/COCOMO
https://en.wikipedia.org/wiki/Stable_Diffusion
https://midjourney.com/
https://openai.com/product/dall-e-2
https://www.goodreads.com/book/show/97030.Six_Thinking_Hats
https://medium.com/usevim/vim-101-completion-compendium-97b4ebc3a45a
https://twitter.com/DocSparse/status/1581461734665367554
////

If I had to name a currently trending topic I would surely pick [ChatGPT][] or rather the
underlying AI model [GPT-3][] with its upcoming pricier and more capable successor [GPT-4][].
Between all these news and probably related to my own technical bubble there is lots of progress
regarding AI-assistants for coding.

I had a look at both [CoPilot][] and [Tabnine][] when they went viral first, but I never tried to
sort my own thoughts about this whole idea.
So in this post I will try to bring these thoughts to paper with both my operational and my
management hat on and it is up to you to decide which [colors][] they have.

== What are these assistants?

The whole idea is actually pretty simple, if we put the inherent complexity of AI aside for now:

We train an AI model on available natural language and source code and allow it to give
recommendations based on a [prompt][] of the actual code an developer writes.

So if you want to use a derogatory term here it is an auto-completion on steroids.

== What are they capable of?

The results of the code suggestions are nothing short of astonishing and can complete words,
single sentences and also provide whole bodies for methods and functions.

Another autocompleter doesn't sound that fancy and every fellow [omnicompletion][] user can confirm
the old ways work pretty well, but the actual prowess of the new AI-based systems is easy to
dismiss until you have seen it in action.

Let us start with some easy examples.

Here is the typical fun of adding the proper annotations for [OpenAPI][]:

++++
<div class="imageblock">
    <div class="content">
        <img data-gifffer="/assets/images/coding_with_ai/code_completion1.gif" />
    </div>
</div>
++++

It is also possible to complete more complex lines with a visibly worse hit and miss ratio:

++++
<div class="imageblock">
    <div class="content">
        <img data-gifffer="/assets/images/coding_with_ai/code_completion2.gif" />
    </div>
</div>
++++

[NOTE]
====
On a side note: I also used Tabnine for this blog post just to demonstrate it is entirely possible
to write natural language with it:
image:natural_language.png[]
====

== Things to consider

=== Faster time to market

AI can rapidly speed up the creation of boilerplate code and repeated stuff which cannot easily be
put into other artifacts like libraries or templates like [Maven Archetype][] for
[Java][]-based software.

=== Recruiting and Training

=== License fees and training costs

My own experience is limited to CoPilot and Tabnine, but there are companies providing these
services aplenty.
Here are the current prices for both services - based on data at the time of this post's
writing:

|===
|Service|Individual costs (per month)|Business costs (per month per user)
|CoPilot|$10 (or $100 per year)|$19
|TabNine|$0 Starter / $12 Pro|Let's talk
|===

NOTE: Sources: <https://github.com/features/copilot>, <https://www.tabnine.com/pricing>

These are just the plain service costs and don't include further costs to train staff or to create
proper company guidelines how to actually use this technology.

=== Copyright

Copyright is a major concern here and if we have a look at the apparent disputes with the phenomenal
results of [Stable Fusion][]-based AI like [DALL-E][] or [MidJourney][] and the original artists
for the training data of theses models there are lots of decisions still to be made.

This is probably worse for software:

image::copyright.png[]

=== Isolated customer systems

Dependent on the customer and obviously the industry there are legal limits which code can be used
as training data and how the data can be accessed.

Training a model with data that is hidden inside of customer systems, where usually is no option
to install non-governed software.

=== Code duplication


=== Performance

Many services provide multiple ways of using the language model - but it typically boils down to
either run it locally or just use the cloud with more processing power and also more suggestions
due to the availability of training data.

Dependent on the size of the actual data the requirements for compute can have a huge impact.

Following screenshot shows the process view of TabNine on my local machine while typing inside
of this blog post:

image::resources.png[]

There are quite few reports of problems about performance:

<https://github.com/codota/TabNine/issues/43>

== Conclusion

In our industry there still exists the myth of a **10x developer** which is a really loose
description for an individual contributor with coding super powers.
I am not entirely sure, if this is solely based on the actual coded lines (hello [COCOMO][]) or
the quality of the code.

I think in some ways it kind of behaves like copying code from [StackOverflow][] and it isn't clear,
if the code was provided in the question or in the accepted answer.

Super powers are never free - the same is true for the processing and storage power that is
required here from [OpenAI][] and additionally there are license costs.
