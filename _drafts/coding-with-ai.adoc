---
layout: post
title: Coding with AI
date: 2023-03-30 17:22 +0100
last_updated: 2023-03-30 17:22 +0100
author: Christoph Kappel
tags: tech ai
categories: myself
toc: true
---
:imagesdir: /assets/images/coding_with_ai
:figure-caption!:

////
https://github.com/features/copilot
https://www.tabnine.com/pricing
https://en.wikipedia.org/wiki/COCOMO
https://en.wikipedia.org/wiki/Stable_Diffusion
https://midjourney.com/
https://openai.com/product/dall-e-2
https://www.goodreads.com/book/show/97030.Six_Thinking_Hats
https://medium.com/usevim/vim-101-completion-compendium-97b4ebc3a45a

https://blog.aspiresys.com/infrastructure-managed-services/why-ai-powered-code-completion-tools-are-essential-for-your-devsecops-strategy/
https://about.gitlab.com/blog/2023/03/23/ai-assisted-code-suggestions/
https://thenewstack.io/github-copilot-a-powerful-controversial-autocomplete-for-developers/
https://nordcloud.com/tech-community/coding-copilot-ai-autocompletion/
https://amistrongeryet.substack.com/p/gpt-4-capabilities
https://slashdot.org/software/ai-coding-assistants/?sort=rating_avg
////

Trending topics at the moment are surely everything related to [ChatGPT][] and if we widen the
scope to include the underlying AI model [GPT-3][] and its pricier and more capable successor
[GPT-4][] is is somehow difficult to keep up with all the news.
And between all these articles AI-assistants for coding generates lots of traction as well.

The market is already pretty much flooded with different services and products.
[Slashdot][] alone lists three paginated pages of tools and I had a tough time to pick the few I
actually want to give a try.

I ultimately picked [TabNine][], because of its free tier and it was actually the first I ever
gave a spin and [CoPilot][], due to the vast amount of training data available and also a chance
of my own repositories used for training.

So in this post I will try to bring these thoughts to paper with both my operational and my
management hat on and it is up to you to decide which [color of the six][] they are.

== What are these assistants?

The whole idea is actually pretty simple, if we put the inherent complexity of AI aside for now:

We train a large language model ([LLM][]) on our available text (natural language) and source
code and [prompt][] for recommendations based on the actual code we write.

== What are they capable of?

The results of the code suggestions are nothing short of astonishing and can complete words,
single sentences and also provide whole bodies for methods and functions.

++++
<table>
    <tr>
        <td>TabNine</td>
        <td>CoPilot</td>
    </tr>
    <tr>
        <td>
            <div class="imageblock">
                <div class="content">
                    <img data-gifffer="/assets/images/coding_with_ai/code_completion1.gif" />
                </div>
            </div>
        </td>
        <td>
            <div class="imageblock">
                <div class="content">
                    <img data-gifffer="/assets/images/coding_with_ai/code_completion2.gif" />
                </div>
            </div>
        </td>
    </tr>
</table>
++++

It is also possible to use the suggestions as a kind of [autocomplete][] and [snippet][] library
like CoPilot here beautifully demonstrates even with [Markdown][] link syntax:

image::natural_language.png[]

When you are in full flow the completion can be a nice addition, until you see for yourself where
the limits are - or like CoPilot wonders by itself:

image::not_capable.png[]

I think his quote sums this up pretty nicely:

[quote,'https://amistrongeryet.substack.com/p/gpt-4-capabilities']
What GPT-4 Does Is Less Like "Figuring Out" and More Like "Already Knowing".
Yes, It's a Stochastic Parrot, But Most Of The Time You Are Too, And It's Memorized a Lot More More Than You Have

== Things to consider

Next comes an unsorted list of thoughts about the whole idea with hopefully mostly rational white
hat thinking and with my personal opinion limited to the conclusion part after that.

=== Faster time to market

AI can rapidly speed up the creation of boilerplate code and repeated stuff which cannot easily be
put into other artifacts like libraries or templates like [Maven Archetype][] for [Java][]-based
software.

In a closed cosmos the suggestions can then be limited to own software and be a kind of completion
library to assemble functional software like with the low-code/no-code approach on a more
technical level.

=== Training and recruiting

AI completion allows to write functional software even when you aren't well-versed in the given
language and this can make programming in general more approachable for beginners.

This allows to learn something new without reading large manuals and have a shorter fail/success
cycle which benefits learning.

And this by itself can also generate more interest and lure people into the business.

=== License fees and training costs

Adding tools to the corporate world usually induces license fees and this applies here as well.

There a companies providing these services aplenty, but let us just check the price tags of the two
services that I've used for this post.

|===
|Service|Individual costs (per month)|Business costs (per month per user)
|CoPilot|$10 (or $100 per year)|$19
|TabNine|$0 Starter / $12 Pro|Let's talk
|===

NOTE: Sources: <https://github.com/features/copilot>, <https://www.tabnine.com/pricing>

Apart from the plain license and service costs there might be additional costs to train staff or
to create company guidelines how to actually use this technology.

=== Copyright

There are many pending lawsuits and copyright claims regarding the use of [Stable Diffusion][]-based
AI like [DALL-E][] or [MidJourney][].

Normally it is quite difficult to make assumptions about the actual training data, when the case
isn't that obvious like in the example posted on [HackernNews][], with an in-tact watermark
from [GettyImages][]:

[link=https://news.ycombinator.com/item?id=32573523]
.Source <https://news.ycombinator.com/item?id=32573523>
image::watermark.png[width=50%]

NOTE:

This is worse for software, when the original author can be identified easily of literally large
parts of suggested code:

[link=https://news.ycombinator.com/item?id=32573523]
.Source <https://news.ycombinator.com/item?id=32573523>
image::copyright.png[]

=== Isolated customer systems

Dependent on the customer and obviously the industry there are legal limits which code can be used
as training data and how the data can be accessed.

When the data is hidden inside of closed customer systems there is usually no option to install
non-sanctioned software.

=== Code duplication

When any AI assist suggests a solution to a code prompt, it has seen this somewhere else and where
this else is, is something that is probably difficult to find out.

This might either lead to lots of code duplication or to coupling when the code is refactored to
avoid this duplication.

=== Performance

Many services provide multiple ways of using a large language model (LLM) - but it typically boils
down to either run it locally or just use the cloud with more processing power and also more
suggestions due to the availability of training data.

Dependent on the size of the actual data the requirements for compute might have a huge impact.

Following screenshot shows the processes of TabNine on my local machine while typing inside of this
blog post:

image::resources.png[]

Also, there are quite few reports of problems about performance:

<https://github.com/codota/TabNine/issues/43>

=== Security

Re-using code can be a double-edged sword, especially when the actual source is unknown.
This is especially true for pages like [StackOverflow][], when you cannot be sure if the code was
posted in the question or in the accepted answer:

<https://stackoverflow.blog/2019/11/26/copying-code-from-stack-overflow-you-might-be-spreading-security-vulnerabilities/>

== Conclusion

image::nice-try.png[]
.(Nice try, AI!)

If you consider all of the mentioned points it it difficult to make your own mind about it and it
is totally up to the goal you ultimately want to achieve.

For me, one of the weirdest sensations while writing this post is that AI-autocompletion with all
the suggestions kind of changes the way you express yourself and I am not sure if I really like it.

The old ways of using completion systems like [Omnicompletion][] give good and reasonable
suggestions and I don't think my coding speed is somehow related to the speed I can type.

On the other hand any system that helps to reach the levels of the mythic **10x developer**
with coding super powers (I am not entirely sure, if this is solely based on the actual coded lines
(hello [COCOMO][]) or the quality of the code.) is pretty much worth any invest for business
side.

[quote,'https://thenewstack.io/github-copilot-a-powerful-controversial-autocomplete-for-developers/']
Rauch likens the situation to GitHub providing a way of creating an “inline pull request,” where
the submitter is an AI and you're constantly reviewing their proposals, he said.