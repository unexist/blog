---
layout: post
title: MapReduce
#date: %%%DATE%%%
#last_updated: %%%DATE%%%
author: Christoph Kappel
tags: hadoop big-data showcase
categories: tech
toc: true
---
ifdef::asciidoctorconfigdir[]
:imagesdir: {asciidoctorconfigdir}/../assets/images/mapreduce
endif::[]
ifndef::asciidoctorconfigdir[]
:imagesdir: /assets/images/mapreduce
endif::[]
:figure-caption!:
:table-caption!:
:page-liquid:

This is the second part of my [Big Data] series


With the basics laid out in the previous article about the general concepts of [Hadoop][]
and [Big data][] we can focus on the actual compute model [MapReduce][].

== What is MapReduce?

=== Sort and shuffle

++++
{% plantuml %}
' left to right direction
skinparam linetype ortho
' skinparam nodesep 100
' skinparam ranksep 100

rectangle Mapper as map
rectangle Reducer as red

rectangle "HDFS (Replicated)" as hdfs {
  File "Block of Data" as f_block
  File "Output File" as f_out
}

rectangle "Native File System" as fs {
  File "Temp Spill Data" as f_spill
  File "Partitioned Sorted Data" as f_part
  File "Reducer Local Copy" as f_local
}

' Layout

map -d[hidden]-> hdfs
map -r[hidden]-> red
red -d[hidden]-> hdfs
hdfs -r[hidden]-> fs

f_block -r[hidden]-> f_out
f_spill -r[hidden]-> f_part
f_part -r[hidden]-> f_local

' Arrows

f_block -u[#green]-> map: (1)
map -d-> f_spill: (2)
f_spill -u-> map: (2)
map -d-> f_part: (3)

f_part -u-> red: (4)
red -d-> f_local: (5)
f_local -u-> red: (5)
red -d[#red]-> f_out: (6)
{% endplantuml %}
++++

=== Mapper

[source,java]
----
public class TodoMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private final static IntWritable addOne = new IntWritable(1);

    private Text dueDate = new Text();
    private ObjectMapper mapper = new ObjectMapper();

    protected void map(LongWritable key, Text value, Context context)
            throws java.io.IOException, InterruptedException
    {
        try {
            Todo todo = this.mapper.readValue(value.toString(), Todo.class);

            dueDate.set(todo.getDueDate().getDue()
                    .format(DateTimeFormatter.ofPattern(DueDate.DATE_PATTERN)));

            context.write(dueDate, addOne);
        } catch (JsonProcessingException e) {
            /* Do nothing */
        }
    }
}
----

=== Reducer

[source,java]
----
public class TodoReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws java.io.IOException,
            InterruptedException
    {
        int sum = 0;

        for (IntWritable value : values) {
            sum += value.get();
        }

        context.write(key, new IntWritable(sum));
    }
}
----

=== Testing

[source,java]
----
public class TodoMapperReducerTest {
    final static String RECORD =
            "{\"title\":\"string\",\"description\":\"string\",\"done\":false,\"dueDate\":{\"start\":\"2021-05-07\",\"due\":\"2021-05-07\"},\"id\":0}";

    MapDriver<LongWritable, Text, Text, IntWritable> mapDriver;
    ReduceDriver<Text, IntWritable, Text, IntWritable> reduceDriver;
    MapReduceDriver<LongWritable, Text, Text, IntWritable, Text, IntWritable> mapReduceDriver;

    @Before
    public void setUp() {
        TodoMapper mapper = new TodoMapper();
        TodoReducer reducer = new TodoReducer();

        mapDriver = MapDriver.newMapDriver(mapper);
        reduceDriver = ReduceDriver.newReduceDriver(reducer);
        mapReduceDriver = MapReduceDriver.newMapReduceDriver(mapper, reducer);
    }

    @Test
    public void shouldVerifyMapper() throws IOException {
        mapDriver.withInput(new LongWritable(), new Text(RECORD));
        mapDriver.withOutput(new Text("2021-05-07"), new IntWritable(1));
        mapDriver.runTest();
    }

    @Test
    public void shouldVerifyReducer() throws IOException {
        List<IntWritable> values = new ArrayList<IntWritable>();

        values.add(new IntWritable(1));
        values.add(new IntWritable(1));

        reduceDriver.withInput(new Text("2021-05-07"), values);
        reduceDriver.withOutput(new Text("2021-05-07"), new IntWritable(2));
        reduceDriver.runTest();
    }

    @Test
    public void shouldVerfiyMapAndReduce() throws IOException {
        mapReduceDriver.withInput(new LongWritable(), new Text(RECORD));

        List<IntWritable> values = new ArrayList<IntWritable>();

        values.add(new IntWritable(1));
        values.add(new IntWritable(1));

        mapReduceDriver.withOutput(new Text("2021-05-07"), new IntWritable(1));
        mapReduceDriver.runTest();
    }
}
----

== Conclusion

All examples can be found here:

<https://github.com/unexist/showcase-hadoop-cdc-quarkus/>

[bibliography]
== Bibliography

* [[[hadooparch]]] Mark Grover, Ted Malask, Jonathan Seidman, Gwen Shapira, Hadoop Application Architectures, O'Reilly 2015