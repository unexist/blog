---
layout: post
title: Big Data
date: %%%DATE%%%
last_updated: %%%DATE%%%
author: Christoph Kappel
tags: showcase
categories: showcase hadoop hive iceberg debezium
toc: true
---
:imagesdir: /assets/images/big_data
:figure-caption!:
:table-caption!:

```
https://github.com/unexist/showcase-hadoop-cdc-quarkus/blob/master/podman/hadoop_hive_spark/Dockerfile
https://www.linkedin.com/pulse/musl-libc-alpines-greatest-weakness-rogan-lynch/
https://wiki.musl-libc.org/functional-differences-from-glibc.html
```

Looking into something more deeply usually has the nice benefit of completely changing your own
mind about it.
And this can ultimately promote something from a mere [buzzword][] to a something nice with
interesting technical implications.

I never had much contact with the general topic of [Data Lakes][] before, but had to fill in some
blanks in preparation for a meeting with a prospect.
After reading some books and blog posts about the overall idea I pretty much wanted to start
playing with it.
Setting everything up was a challenge by itself, but the more difficult one is how does the data
gets there in the first place?

So in this blog post we are going to set up a single-container data-lake and play with two ways of
moving data from our usual [demo application][] into it.

== Setting everything up

Although the [Dockerfile][] is quite huge, there isn't much complexity involved and I'd like to
use this paragraph to talk about some fun issues I had with it.

=== Alpine and Musl

The first bigger issues that I faced is the incompatibility of the C-based parts of the datanodes
with the default [libc][] implementation of [Alpine][].
[Musl][] is an excellent choice due to its small storage footprint, which happens to be one of the
concerns with containers, but is not without problems.
There are some differences which can to lead to surprising issues and it is never a bad to idea to
check [this curated list][] for more information about it.

[quote,'https://martinheinz.dev/blog/92']
By using Alpine, you're getting "free" chaos engineering for your cluster.

=== Podman removed capabilities

One of the drawbacks of using software in a **rolling-updaty-way** is that you run head first into
every breaking change, unless you make it a good habit of checking changelogs before doing the
actual update.
Needless to say I didn't do that and discoverd a nice change introduced in [Podman][] v`4.4.1`.

After updating my local Podman installation I couldn't start [sshd][] inside of my container
anymore and [Hadoop][] and friends rely heavily on it for communication between nodes:

[source,log]
----
ssh: Connection closed by 127.0.0.1 port 22
sshd: chroot("/run/sshd"): Operation not permitted [preauth]
----

I'd like to say seeing this error poiunted me directly to the changelog of Podman, but unfortunately
I had to debug some time and cannot really remember
I cannot exactly tell how I

[link=https://github.com/containers/podman/blob/main/RELEASE_NOTES.md]
.Source: https://github.com/containers/podman/blob/main/RELEASE_NOTES.md
image::podman_capabilites.png[]

== Debezium, the WAL and an Iceberg

== Scala with a Spark